{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ba7ace",
   "metadata": {
    "papermill": {
     "duration": 0.00629,
     "end_time": "2023-05-06T14:15:33.724667",
     "exception": false,
     "start_time": "2023-05-06T14:15:33.718377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Time series data set (with PyQrack quantum associative memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561327b8",
   "metadata": {
    "papermill": {
     "duration": 0.005581,
     "end_time": "2023-05-06T14:15:33.736199",
     "exception": false,
     "start_time": "2023-05-06T14:15:33.730618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\"PyQrack\" is a pure Python language standard wrapper for the (C++11) Qrack quantum computer simulator library. PyQrack exposes a \"quantum neuron\" called \"`QrackNeuron`.\" (Its API reference is [here](https://pyqrack.readthedocs.io/en/latest/autoapi/pyqrack/qrack_neuron/index.html).) We'd like to model a simple data set to achieve a proof-of-concept of using `QrackNeuron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3b16fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:33.751736Z",
     "iopub.status.busy": "2023-05-06T14:15:33.750834Z",
     "iopub.status.idle": "2023-05-06T14:15:46.465965Z",
     "shell.execute_reply": "2023-05-06T14:15:46.464685Z"
    },
    "papermill": {
     "duration": 12.726889,
     "end_time": "2023-05-06T14:15:46.469062",
     "exception": false,
     "start_time": "2023-05-06T14:15:33.742173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pyqrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd865f4",
   "metadata": {
    "papermill": {
     "duration": 0.006696,
     "end_time": "2023-05-06T14:15:46.482688",
     "exception": false,
     "start_time": "2023-05-06T14:15:46.475992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, load the data set into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb6ebbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:46.498796Z",
     "iopub.status.busy": "2023-05-06T14:15:46.497549Z",
     "iopub.status.idle": "2023-05-06T14:15:46.967618Z",
     "shell.execute_reply": "2023-05-06T14:15:46.966505Z"
    },
    "papermill": {
     "duration": 0.480497,
     "end_time": "2023-05-06T14:15:46.969853",
     "exception": false,
     "start_time": "2023-05-06T14:15:46.489356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store    Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  733808    1643690.90             0        42.31       2.572   \n",
      "1      1  733815    1641957.44             1        38.51       2.548   \n",
      "2      1  733822    1611968.17             0        39.93       2.514   \n",
      "3      1  733829    1409727.59             0        46.63       2.561   \n",
      "4      1  733836    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n",
      "Number of observations:  6435\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('time-series/time-series.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y').apply(lambda x:x.toordinal())\n",
    "# df = df.dropna()\n",
    "\n",
    "print(df.head())\n",
    "print(\"Number of observations: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632139d1",
   "metadata": {
    "papermill": {
     "duration": 0.006401,
     "end_time": "2023-05-06T14:15:46.983305",
     "exception": false,
     "start_time": "2023-05-06T14:15:46.976904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Separate the dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef35d6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:46.999330Z",
     "iopub.status.busy": "2023-05-06T14:15:46.998548Z",
     "iopub.status.idle": "2023-05-06T14:15:47.009374Z",
     "shell.execute_reply": "2023-05-06T14:15:47.008361Z"
    },
    "papermill": {
     "duration": 0.021619,
     "end_time": "2023-05-06T14:15:47.011759",
     "exception": false,
     "start_time": "2023-05-06T14:15:46.990140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = ['Holiday_Flag', 'Store', 'Weekly_Sales', 'Temperature', 'Fuel_Price']\n",
    "dep_key = 'Date'\n",
    "\n",
    "X = df[keys]\n",
    "y = df[dep_key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca99de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.sample(frac = 1/2)\n",
    "test=df.drop(train.index)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "X = train[keys]\n",
    "y = train[dep_key]\n",
    "\n",
    "X_test = test[keys]\n",
    "y_test = test[dep_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83efb4a",
   "metadata": {
    "papermill": {
     "duration": 0.006585,
     "end_time": "2023-05-06T14:15:47.025184",
     "exception": false,
     "start_time": "2023-05-06T14:15:47.018599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ideally, we'd like to make an improvement on the goodness-of-fit of multiple linear regression, with PyQrack's `QrackNeuron`. At the very least, to show that `QrackNeuron` can be viable for modeling a data set, we'd like to show somehwat comparable performance to multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcd673",
   "metadata": {
    "papermill": {
     "duration": 0.006554,
     "end_time": "2023-05-06T14:15:47.038739",
     "exception": false,
     "start_time": "2023-05-06T14:15:47.032185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "PyQrack's `QrackNeuron` can only work with discrete, binary data. To model this or any data set, we have to reduce it to a simple, discrete, binary form.\n",
    "\n",
    "We'll try to model the data set via \"(quantum) associative memory.\" There are several statistical considerations, to avoid overfit.\n",
    "\n",
    "Firstly, each possible discretized independent variable permutation input trains an independent parameter of a `QrackNeuron`. If a `QrackNeuron` has never seen a specific, exact permutation of input bits, it has no information about them at all, so its prediction defaults to \"maximal superposition,\" (i.e. a totally random guess). Therefore, we'd like to keep our number of possible distinct inputs significantly fewer in number than our observation rows, when we discretize our indepedent variables.\n",
    "\n",
    "Satisfying the first consideration, we secondly discretize our dependent variable to have exactly as many possible discrete values as possible distinct inputs. (We guess that this loses the least information about the dependent variable, while we still have enough observations to fully train our network.)\n",
    "\n",
    "Thirdly, our learning rate should should just barely \"saturate\" the learned parameters of our (quantum) associative memory. As a learning volatility parameter (\"`eta`\") of `1/2` \"fully trains\" one parameter of a `QrackNeuron` between input qubits and output qubit, on average, this implies that we might set `eta` to `1/2` times `2` to the power of input qubits (summed across all predictors) divided by the number of observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f102bacf",
   "metadata": {
    "papermill": {
     "duration": 0.006609,
     "end_time": "2023-05-06T14:15:47.098509",
     "exception": false,
     "start_time": "2023-05-06T14:15:47.091900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At a baseline, our first choice to model this data set might be multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa5de66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:47.113458Z",
     "iopub.status.busy": "2023-05-06T14:15:47.113023Z",
     "iopub.status.idle": "2023-05-06T14:15:48.387109Z",
     "shell.execute_reply": "2023-05-06T14:15:48.385974Z"
    },
    "papermill": {
     "duration": 1.284383,
     "end_time": "2023-05-06T14:15:48.389469",
     "exception": false,
     "start_time": "2023-05-06T14:15:47.105086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Holiday_Flag</td>\n",
       "      <td>60.268998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Store</td>\n",
       "      <td>-0.901014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekly_Sales</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>485.606124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1\n",
       "0  Holiday_Flag   60.268998\n",
       "1         Store   -0.901014\n",
       "2  Weekly_Sales   -0.000011\n",
       "3   Temperature    0.565100\n",
       "4    Fuel_Price  485.606124"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "pd.DataFrame(zip(X.columns, regr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbe7aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:48.406072Z",
     "iopub.status.busy": "2023-05-06T14:15:48.404996Z",
     "iopub.status.idle": "2023-05-06T14:15:48.978240Z",
     "shell.execute_reply": "2023-05-06T14:15:48.976910Z"
    },
    "papermill": {
     "duration": 0.583749,
     "end_time": "2023-05-06T14:15:48.980385",
     "exception": false,
     "start_time": "2023-05-06T14:15:48.396636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression validation R^2:  0.9999999389516051\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "sst = 0\n",
    "ssr = 0\n",
    "for i in range(len(y_pred)):\n",
    "    sst += y_test[i] * y_test[i]\n",
    "    ssr += (y_test[i] - y_pred[i]) * (y_test[i] - y_pred[i])\n",
    "\n",
    "print(\"Multiple linear regression validation R^2: \", 1 - ssr / sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c272a0",
   "metadata": {
    "papermill": {
     "duration": 0.007069,
     "end_time": "2023-05-06T14:15:49.586757",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.579688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To discretize the data, we split it into as many quantiles as `2` to the power of our number of input qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd70f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:49.602786Z",
     "iopub.status.busy": "2023-05-06T14:15:49.602380Z",
     "iopub.status.idle": "2023-05-06T14:15:49.619031Z",
     "shell.execute_reply": "2023-05-06T14:15:49.618101Z"
    },
    "papermill": {
     "duration": 0.027775,
     "end_time": "2023-05-06T14:15:49.621572",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.593797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_qubit_count = 6\n",
    "time_qubit_count = 2\n",
    "in_qubit_count = 3\n",
    "\n",
    "time_bin_count = 1 << time_qubit_count\n",
    "in_key_count = len(keys)\n",
    "in_bin_count = 1 << in_qubit_count\n",
    "in_tot_count = 1 + store_qubit_count + (in_key_count - 2) * in_qubit_count\n",
    "\n",
    "x_bins = []\n",
    "for i in range(2, len(keys)):\n",
    "    key = keys[i]\n",
    "    x_bins.append(np.percentile(X[key], np.arange(0, 100, 100 / in_bin_count)))\n",
    "y_bins = np.percentile(y, np.arange(0, 100, 100 / time_bin_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27cc8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:49.638071Z",
     "iopub.status.busy": "2023-05-06T14:15:49.637239Z",
     "iopub.status.idle": "2023-05-06T14:15:49.643878Z",
     "shell.execute_reply": "2023-05-06T14:15:49.642751Z"
    },
    "papermill": {
     "duration": 0.017263,
     "end_time": "2023-05-06T14:15:49.645974",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.628711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 215359.21   ,  419651.82625,  551809.05   ,  752488.02625,\n",
      "        955465.34   , 1184944.37875, 1412790.78   , 1808226.4225 ]), array([-2.06   , 36.75375, 47.55   , 55.075  , 62.725  , 68.88625,\n",
      "       74.64   , 82.4475 ]), array([2.514  , 2.753  , 2.938  , 3.16275, 3.46   , 3.604  , 3.743  ,\n",
      "       3.891  ])]\n"
     ]
    }
   ],
   "source": [
    "print(x_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af3915a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:49.662170Z",
     "iopub.status.busy": "2023-05-06T14:15:49.661794Z",
     "iopub.status.idle": "2023-05-06T14:15:49.666968Z",
     "shell.execute_reply": "2023-05-06T14:15:49.665971Z"
    },
    "papermill": {
     "duration": 0.015928,
     "end_time": "2023-05-06T14:15:49.669078",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.653150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[733808. 734060. 734312. 734557.]\n"
     ]
    }
   ],
   "source": [
    "print(y_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c0a950",
   "metadata": {
    "papermill": {
     "duration": 0.007099,
     "end_time": "2023-05-06T14:15:49.683330",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.676231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once we have our quantiles, we bin our indepedent training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c027aa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:49.700029Z",
     "iopub.status.busy": "2023-05-06T14:15:49.698930Z",
     "iopub.status.idle": "2023-05-06T14:15:55.997481Z",
     "shell.execute_reply": "2023-05-06T14:15:55.996293Z"
    },
    "papermill": {
     "duration": 6.309712,
     "end_time": "2023-05-06T14:15:56.000126",
     "exception": false,
     "start_time": "2023-05-06T14:15:49.690414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discretize_x(X):\n",
    "    xd = []\n",
    "    for i in X.index:\n",
    "        xd_row = []\n",
    "        xd_row.append(X['Holiday_Flag'][i] == 1)\n",
    "        for p in range(store_qubit_count):\n",
    "            xd_row.append(((i >> p) & 1) == 1)\n",
    "        for ki in range(1, len(keys)):\n",
    "            key = keys[ki]\n",
    "            bn = in_bin_count\n",
    "            offset = 0\n",
    "            while bn > 1:\n",
    "                bn =  bn // 2\n",
    "                b = bn + offset\n",
    "                if X[key][i] < x_bins[ki - 2][b - 1]:\n",
    "                    xd_row.append(False)\n",
    "                else:\n",
    "                    xd_row.append(True)\n",
    "                    offset += bn\n",
    "        xd.append(xd_row)\n",
    "    return xd\n",
    "\n",
    "xd = discretize_x(X)\n",
    "xd_test = discretize_x(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbbfd0",
   "metadata": {
    "papermill": {
     "duration": 0.006897,
     "end_time": "2023-05-06T14:15:56.014547",
     "exception": false,
     "start_time": "2023-05-06T14:15:56.007650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We do the same for our dependent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f01bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:56.030586Z",
     "iopub.status.busy": "2023-05-06T14:15:56.030172Z",
     "iopub.status.idle": "2023-05-06T14:15:59.396360Z",
     "shell.execute_reply": "2023-05-06T14:15:59.395337Z"
    },
    "papermill": {
     "duration": 3.377207,
     "end_time": "2023-05-06T14:15:59.398804",
     "exception": false,
     "start_time": "2023-05-06T14:15:56.021597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discretize_y(y):\n",
    "    yd = []\n",
    "    for i in y.index:\n",
    "        yd_row = []\n",
    "        bn = time_bin_count\n",
    "        offset = 0\n",
    "        while bn > 0:\n",
    "            bn =  bn // 2\n",
    "            b = bn + offset\n",
    "            if y[i] < y_bins[b - 1]:\n",
    "                yd_row.append(False)\n",
    "            else:\n",
    "                yd_row.append(True)\n",
    "                offset += bn\n",
    "        yd.append(yd_row)\n",
    "    return yd\n",
    "\n",
    "yd = discretize_y(y)\n",
    "yd_test = discretize_y(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70e363",
   "metadata": {
    "papermill": {
     "duration": 0.006734,
     "end_time": "2023-05-06T14:15:59.412842",
     "exception": false,
     "start_time": "2023-05-06T14:15:59.406108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We're ready to train our associative memory! (Note that it offers us no particular advantage, in this case, that our \"neurons\" are based on simulated quantum computational gates, though it is possible to predict in \"superposition\" of many rows at once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1433725d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:15:59.428515Z",
     "iopub.status.busy": "2023-05-06T14:15:59.427835Z",
     "iopub.status.idle": "2023-05-06T14:18:22.848306Z",
     "shell.execute_reply": "2023-05-06T14:18:22.846962Z"
    },
    "papermill": {
     "duration": 143.431003,
     "end_time": "2023-05-06T14:18:22.850737",
     "exception": false,
     "start_time": "2023-05-06T14:15:59.419734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3200  out of  3218\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from pyqrack import QrackSimulator, QrackNeuron\n",
    "\n",
    "eta = (1 / 2) * (time_bin_count / y.shape[0])\n",
    "input_indices = list(range(in_tot_count))\n",
    "qsim = QrackSimulator(in_tot_count + time_qubit_count)\n",
    "\n",
    "qft_qubits = {}\n",
    "qft_qubits[keys[0]] = [0]\n",
    "qft_qubits[keys[1]] = []\n",
    "for i in range(2, len(keys)):\n",
    "    qft_qubits[keys[i]] = list(range(i * in_qubit_count, (i + 1) * in_qubit_count))\n",
    "\n",
    "output_layer = []\n",
    "for i in range(time_qubit_count):\n",
    "    output_layer.append(QrackNeuron(qsim, input_indices, in_tot_count + i))\n",
    "\n",
    "# Train the network to associate powers of 2 with their log2()\n",
    "print(\"Learning...\")\n",
    "for i in range(len(xd)):\n",
    "    if ((i + 1) % 100) == 0:\n",
    "        if (i + 1) != 100:\n",
    "            clear_output(wait=True)\n",
    "        print(\"Epoch \", (i + 1), \" out of \", len(xd))\n",
    "    \n",
    "    perm = xd[i]\n",
    "    res = yd[i]\n",
    "\n",
    "    for j in range(time_qubit_count):\n",
    "        qsim.reset_all()\n",
    "        for k in range(in_tot_count):\n",
    "            if perm[k]:\n",
    "                qsim.x(k)\n",
    "        # Transform time domain to Fourier basis\n",
    "        # for key in keys:\n",
    "        #     qsim.iqft(qft_qubits[key])\n",
    "        output_layer[j].learn_permutation(eta, res[j] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90852cbe",
   "metadata": {
    "papermill": {
     "duration": 0.006769,
     "end_time": "2023-05-06T14:18:22.865067",
     "exception": false,
     "start_time": "2023-05-06T14:18:22.858298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's use our neural net, trained on half the data, to try to predict the left-out half of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6285fa1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:18:22.881155Z",
     "iopub.status.busy": "2023-05-06T14:18:22.880399Z",
     "iopub.status.idle": "2023-05-06T14:18:49.325303Z",
     "shell.execute_reply": "2023-05-06T14:18:49.324060Z"
    },
    "papermill": {
     "duration": 26.455679,
     "end_time": "2023-05-06T14:18:49.327672",
     "exception": false,
     "start_time": "2023-05-06T14:18:22.871993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting  3200  out of  3217\n"
     ]
    }
   ],
   "source": [
    "print(\"Should associate each input with its trained output...\")\n",
    "sum_sqr_tot = 0\n",
    "sum_sqr_res = 0\n",
    "for i in range(len(xd_test)):\n",
    "    if ((i + 1) % 100) == 0:\n",
    "        if (i + 1) != 100:\n",
    "            clear_output(wait=True)\n",
    "        print(\"Predicting \", (i + 1), \" out of \", len(xd_test))\n",
    "    \n",
    "    perm = xd_test[i]\n",
    "\n",
    "    qsim.reset_all()\n",
    "    for j in range(in_tot_count):\n",
    "        if perm[j]:\n",
    "            qsim.x(j)\n",
    "        # Transform time domain to Fourier basis\n",
    "        # for key in keys:\n",
    "        #     qsim.iqft(qft_qubits[key])\n",
    "\n",
    "    for j in range(time_qubit_count):\n",
    "        output_layer[j].predict()\n",
    "\n",
    "    bn = time_bin_count\n",
    "    offset = 0\n",
    "    for j in range(time_qubit_count):\n",
    "        bn = bn // 2\n",
    "        offset += bn * qsim.prob(in_tot_count + j) \n",
    "    pred = y_bins[round(offset)]\n",
    "\n",
    "    sum_sqr_tot += y_test[i] * y_test[i]\n",
    "    sum_sqr_res += (y_test[i] - pred) * (y_test[i] - pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf6f94",
   "metadata": {
    "papermill": {
     "duration": 0.007161,
     "end_time": "2023-05-06T14:18:49.342548",
     "exception": false,
     "start_time": "2023-05-06T14:18:49.335387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How does this compare to the validation R^2 of multiple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17125ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T14:18:49.359740Z",
     "iopub.status.busy": "2023-05-06T14:18:49.358567Z",
     "iopub.status.idle": "2023-05-06T14:18:49.365319Z",
     "shell.execute_reply": "2023-05-06T14:18:49.364092Z"
    },
    "papermill": {
     "duration": 0.01765,
     "end_time": "2023-05-06T14:18:49.367480",
     "exception": false,
     "start_time": "2023-05-06T14:18:49.349830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QrackNeuron training R^2:  0.9999998049609718\n",
      "Multiple linear regression training R^2:  0.9999999389516051\n",
      "Multiple linear regression outperformed QrackNeuron quantum associative memory.\n"
     ]
    }
   ],
   "source": [
    "print(\"QrackNeuron training R^2: \", 1 - sum_sqr_res / sum_sqr_tot)\n",
    "print(\"Multiple linear regression training R^2: \", 1 - ssr / sst)\n",
    "if (1 - sum_sqr_res / sum_sqr_tot) > (1 - ssr / sst):\n",
    "    print(\"QrackNeuron quantum associative memory outperformed multiple linear regression.\")\n",
    "else:\n",
    "    print(\"Multiple linear regression outperformed QrackNeuron quantum associative memory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 206.417493,
   "end_time": "2023-05-06T14:18:50.398278",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-06T14:15:23.980785",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
