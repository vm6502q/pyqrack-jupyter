{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composed-midwest",
   "metadata": {},
   "source": [
    "# Quantum perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-scott",
   "metadata": {},
   "source": [
    "You need the `pyqrack` package to run this notebook. [`vm6502q/pyqrack`](https://github.com/vm6502q/pyqrack) is a pure Python wrapper on the [`vm6502q/qrack`](https://github.com/vm6502q/qrack) quantum computer simulation framework core library. The preferred method of installation is from source code, at those GitHub repositories, but a package with default build precompiled binaries is available on [pypi](https://pypi.org/project/pyqrack/0.2.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, if your Jupyter installation uses pip:\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pyqrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-athletics",
   "metadata": {},
   "source": [
    "[`QrackSimulator`](https://github.com/vm6502q/pyqrack/blob/main/pyqrack/qrack_simulator.py) is the \"workhorse\" of the `pyqrack` package. It instantiates simulated \"registers\" of qubits that we can act basic quantum gates between, to form arbitrary universal quantum circuits.\n",
    "\n",
    "[`QrackNeuron`](https://github.com/vm6502q/pyqrack/blob/main/pyqrack/qrack_neuron.py) exposes the `QNeuron` class of the C++ Qrack library. With this class, the synaptic cleft is modeled as a single qubit, which might be a subsystem of a larger pure state. \"Uniformly controlled\" or \"single-qubit-target multiplexer\" gates condition a single output qubit on the general quantum state of an abitrarily large number of input qubits.\n",
    "\n",
    "(For an API reference for `QrackNeuron` and PyQrack in general, see [https://pyqrack.readthedocs.io/en/latest/autoapi/pyqrack/qrack_neuron/index.html](https://pyqrack.readthedocs.io/en/latest/autoapi/pyqrack/qrack_neuron/index.html). For a list of available `QrackNeuron` activation functions, see [https://pyqrack.readthedocs.io/en/latest/autoapi/pyqrack/neuron_activation_fn/index.html](https://pyqrack.readthedocs.io/en/latest/autoapi/pyqrack/neuron_activation_fn/index.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranging-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device #0, Loaded binary from: /home/iamu/.qrack/qrack_ocl_dev_Intel(R)_UHD_Graphics_[0x9bc4].ir\n",
      "Device #1, Loaded binary from: /home/iamu/.qrack/qrack_ocl_dev_NVIDIA_GeForce_RTX_3080_Laptop_GPU.ir\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pyqrack import QrackSimulator, QrackNeuron, NeuronActivationFn\n",
    "\n",
    "qsim_ex = QrackSimulator(2)\n",
    "qneuron = QrackNeuron(qsim_ex, [0], 1)\n",
    "qneuron.set_angles([0.0, math.pi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665514e6",
   "metadata": {},
   "source": [
    "This neuron, with these synaptic parameters, is equivalent to a CNOT gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cef4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  0 , Output:  0\n",
      "Input:  1 , Output:  1\n"
     ]
    }
   ],
   "source": [
    "for perm in range(2):\n",
    "\n",
    "    # Set input\n",
    "    qsim_ex.reset_all()\n",
    "    if perm & 1:\n",
    "        qsim_ex.x(0)\n",
    "\n",
    "    # Feed-forward\n",
    "    qneuron.predict(r=False)\n",
    "\n",
    "    # Measure output\n",
    "    comp = qsim_ex.m(1)\n",
    "\n",
    "    print(\"Input: \", perm, \", Output: \", comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c4324",
   "metadata": {},
   "source": [
    "After the above, the following code always produces a Bell pair that would collapse into the same output value as input, for the Hadamard initialization of the input qubit, to activate both |0> and |1> input synaptic parameters at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587f44df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  1 , Output:  1\n"
     ]
    }
   ],
   "source": [
    "# Feed-forward\n",
    "qsim_ex.reset_all()\n",
    "qsim_ex.h(0)\n",
    "qneuron.predict(r=False)\n",
    "print(\"Input: \", qsim_ex.m(0), \", Output: \", qsim_ex.m(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b78cc2",
   "metadata": {},
   "source": [
    "An `eta` value of 1/2 will fully train the default (\"ignorant\") state of a synaptic parameter between the combination of inputs and output.\n",
    "\n",
    "The term \"perceptron\" refers to one of the simplest possible neuromorphic computing models: the entire \"neural network\" is a single \"neuron.\" Despite the simplicity of the \"network,\" a (\"classical\" or \"quantum\") virtual neuron can do useful work on its own, for simple problems.\n",
    "\n",
    "Our \"quantum perceptron\" acts on \"synaptic clefts\" which are each exactly one \"qubit\" of information. The perceptron accepts an arbitrary number of (synaptic) qubit inputs and acts on a single (synaptic) qubit output. For **each permutation** of input qubits, we train one **\"synaptic parameter\"** that controls the rotation of the output qubit (around the Pauli Y) axis.\n",
    "\n",
    "For each neuron in our network, we can also specify a nonlinear \"activation function,\" among several choices, meant to mimic behavior like the all-or-nothing \"firing potential\" of a biological neuron, or else introduce novel nonlinear behavior to the activation of our neurons. To simulate a (\"step function\") all-or-nothing firing potential, we offer `NeuronActivationFn.Generalized_Logistic`, which also requires an `alpha` parameter that controls the \"steepness\" of the activation function. `alpha` should typically be greater than `1.0`, and, the higher we set the parameter, the closer the activation function of neuron comes to all-or-nothing, being \"sticky\" at the states |0>, and |1>, as well as at their equal superpositions of same and opposite phase, |+> and |->. From a default state of \"ignorance,\" we call the starting state of our neuron |+>; \"full\" training with `eta=1/2` brings us to |0> or |1> state; a second \"full\" training step might take us to |->, opposite on the Bloch sphere from our starting point of |+>.\n",
    "\n",
    "Our default activation function is `Sigmoid`, indicating that we treat each \"synaptic parameter\" as just a literal and exact rotation angle for the output qubit around the Pauli Y axis. The `Generalized_Logistic` activation function makes no difference to our example below, but it's perfectly permissible with very high `alpha` parameter, as we intend for our perceptron to \"stick\" at values of |0> and |1>, once trained to produce our intended outputs.\n",
    "\n",
    "We can train a single `QrackNeuron` instance to recognize when its inputs, as an integer, are a power of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9407b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning (to recognize powers of 2)...\n",
      "Epoch  1  out of  16\n",
      "Epoch  2  out of  16\n",
      "Epoch  3  out of  16\n",
      "Epoch  4  out of  16\n",
      "Epoch  5  out of  16\n",
      "Epoch  6  out of  16\n",
      "Epoch  7  out of  16\n",
      "Epoch  8  out of  16\n",
      "Epoch  9  out of  16\n",
      "Epoch  10  out of  16\n",
      "Epoch  11  out of  16\n",
      "Epoch  12  out of  16\n",
      "Epoch  13  out of  16\n",
      "Epoch  14  out of  16\n",
      "Epoch  15  out of  16\n",
      "Epoch  16  out of  16\n",
      "\n",
      "Should be close to 1 for powers of two, and close to 0 for all else...\n",
      "Permutation:  0 , Probability:  0.0\n",
      "Permutation:  1 , Probability:  1.0\n",
      "Permutation:  2 , Probability:  1.0\n",
      "Permutation:  3 , Probability:  0.0\n",
      "Permutation:  4 , Probability:  0.9999999403953552\n",
      "Permutation:  5 , Probability:  0.0\n",
      "Permutation:  6 , Probability:  0.0\n",
      "Permutation:  7 , Probability:  0.0\n",
      "Permutation:  8 , Probability:  1.0\n",
      "Permutation:  9 , Probability:  0.0\n",
      "Permutation:  10 , Probability:  0.0\n",
      "Permutation:  11 , Probability:  0.0\n",
      "Permutation:  12 , Probability:  0.0\n",
      "Permutation:  13 , Probability:  0.0\n",
      "Permutation:  14 , Probability:  0.0\n",
      "Permutation:  15 , Probability:  0.0\n",
      "\n",
      "(Superposition of all powers of 2) Probability:  1.0\n"
     ]
    }
   ],
   "source": [
    "eta = 1 / 2\n",
    "input_count = 4\n",
    "input_power = 1 << input_count\n",
    "input_log = 2\n",
    "\n",
    "def set_permutation(qsim, perm, len):\n",
    "    qsim.reset_all()\n",
    "    for i in range(len):\n",
    "        if (perm >> i) & 1:\n",
    "            qsim.x(i)\n",
    "\n",
    "qsim = QrackSimulator(input_count + 1)\n",
    "\n",
    "input_indices = list(range(input_count))\n",
    "\n",
    "q_perceptron = QrackNeuron(qsim, input_indices, input_count, NeuronActivationFn.Generalized_Logistic, alpha=100.0)\n",
    "\n",
    "# Train the network to recognize powers of 2\n",
    "print(\"Learning (to recognize powers of 2)...\")\n",
    "for perm in range(input_power):\n",
    "    print(\"Epoch \", (perm + 1), \" out of \", input_power)\n",
    "\n",
    "    set_permutation(qsim, perm, input_count + 1)\n",
    "\n",
    "    isPowerOf2 = ((perm != 0) and ((perm & (perm - 1)) == 0))\n",
    "    q_perceptron.learn_permutation(eta, isPowerOf2)\n",
    "\n",
    "print()\n",
    "print(\"Should be close to 1 for powers of two, and close to 0 for all else...\")\n",
    "for perm in range(input_power):\n",
    "\n",
    "    set_permutation(qsim, perm, input_count + 1)\n",
    "\n",
    "    print(\"Permutation: \", perm, \", Probability: \", q_perceptron.predict())\n",
    "\n",
    "# Now, we prepare a superposition of all available powers of 2, to predict.\n",
    "powersOf2 = [(1 << i) for i in range(input_count)]\n",
    "\n",
    "qsim2 = QrackSimulator(input_log)\n",
    "\n",
    "qsim.compose(qsim2, list(range(input_count + 1, input_count + 1 + input_log)))\n",
    "set_permutation(qsim, 1 << (input_count + 1), input_count + 1 + input_log)\n",
    "for i in range(input_log):\n",
    "    qsim.h(input_count + 1 + i)\n",
    "qsim.lda(list(range(input_count + 1, input_count + 1 + input_log)), list(range(0, input_count)), powersOf2)\n",
    "for i in range(input_log):\n",
    "    qsim.h(input_count + 1 + i)\n",
    "qsim.dispose(list(range(input_count + 1, input_count + 1 + input_log)))\n",
    "\n",
    "print()\n",
    "print(\"(Superposition of all powers of 2) Probability: \", q_perceptron.predict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
